{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ติดตั้ง Tool\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bw7MbuIemZtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pythainlp\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchtext==0.6.0\n",
        "\n",
        "import torchtext\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "id": "pspQtfHVkLUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "979e70ba-874f-4e37-8406-d2909d1b001d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.0.1-py3-none-any.whl (17.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.2.2)\n",
            "Installing collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.0.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.4.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ตั้งค่า path ของไฟล์\n",
        "file_path = '/content/cleaned_thai_cyberbullying.csv'\n",
        "\n",
        "# โหลดไฟล์ CSV เป็น DataFrame\n",
        "df = pd.read_csv('/content/cleaned_thai_cyberbullying.csv')\n",
        "\n",
        "# แสดงข้อมูล\n",
        "df.head(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "107IsFI_WPN7",
        "outputId": "cae09535-e79f-4220-fd9e-67871d5d7c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                       text_cleaned  label  \\\n",
              "0         1617                 อิตุ๊ดมึงยังไม่ได้ดูคอนผัวเลยอิสัส      1   \n",
              "1         2748  ยอนโฮเหล่าเวร์เรอร์แฮปปี้เวรี่คริสต์มาสหวังว่า...      0   \n",
              "2         4312              แฮปปี้เฉาก๊วยเหนียวหนึบหวานเย็นชื่นใจ      0   \n",
              "3         5191                              ให้อิตุ๊ดดูชอบตบอิเก๋      1   \n",
              "4         6463                                   อิตุ๊ดใครเมียมึง      1   \n",
              "..         ...                                                ...    ...   \n",
              "95        9175                               บิทแฮปปี้โรสเดย์โซฮี      0   \n",
              "96        6690  ปั่นปั่นปั่นกลับบ้านแฮปปี้พ่อแม่ไม่ดุไม่บ่นบ้า...      0   \n",
              "97        3766  โอ๊ยๆๆๆอิตุ๊ดเด็กกรุขำหนักมากจริงๆอิดอกจะอ้วกก...      1   \n",
              "98         952  คนแบบนายเอกนิยายมันมีจริงนะนี่เคยเจอเป็นผชตัวเ...      1   \n",
              "99        2733                               ปีนี้แฮปปี้มากๆเลยนะ      0   \n",
              "\n",
              "                                                 text  \n",
              "0        อิ ตุ๊ด มึง ยัง ไม่ ได้ ดู คอน ผัว เลย อิสัส  \n",
              "1   ยอน โฮ เหล่า เวร์เรอร์ แฮปปี้ เว รี่ คริสต์มาส...  \n",
              "2           แฮปปี้ เฉาก๊วย เหนียวหนึบ หวานเย็น ชื่นใจ  \n",
              "3                        ให้ อิ ตุ๊ด ดู ชอบ ตบ อิ เก๋  \n",
              "4                                อิ ตุ๊ด ใคร เมีย มึง  \n",
              "..                                                ...  \n",
              "95                         บิท แฮปปี้ โร ส เดย์ โซ ฮี  \n",
              "96  ปั่น ปั่น ปั่น กลับบ้าน แฮปปี้ พ่อแม่ ไม่ ดุ ไ...  \n",
              "97  โอ๊ย อิ ตุ๊ด เด็ก กรุ ขำ หนัก มาก จริง อิด อก ...  \n",
              "98  คน แบบ นาย เอก นิยาย มัน มี จริง นะ นี่ เคย เจ...  \n",
              "99                           ปี นี้ แฮปปี้ มาก เลย นะ  \n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5e7d81e-01f0-4662-92dc-421a310339b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_cleaned</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1617</td>\n",
              "      <td>อิตุ๊ดมึงยังไม่ได้ดูคอนผัวเลยอิสัส</td>\n",
              "      <td>1</td>\n",
              "      <td>อิ ตุ๊ด มึง ยัง ไม่ ได้ ดู คอน ผัว เลย อิสัส</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2748</td>\n",
              "      <td>ยอนโฮเหล่าเวร์เรอร์แฮปปี้เวรี่คริสต์มาสหวังว่า...</td>\n",
              "      <td>0</td>\n",
              "      <td>ยอน โฮ เหล่า เวร์เรอร์ แฮปปี้ เว รี่ คริสต์มาส...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4312</td>\n",
              "      <td>แฮปปี้เฉาก๊วยเหนียวหนึบหวานเย็นชื่นใจ</td>\n",
              "      <td>0</td>\n",
              "      <td>แฮปปี้ เฉาก๊วย เหนียวหนึบ หวานเย็น ชื่นใจ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5191</td>\n",
              "      <td>ให้อิตุ๊ดดูชอบตบอิเก๋</td>\n",
              "      <td>1</td>\n",
              "      <td>ให้ อิ ตุ๊ด ดู ชอบ ตบ อิ เก๋</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6463</td>\n",
              "      <td>อิตุ๊ดใครเมียมึง</td>\n",
              "      <td>1</td>\n",
              "      <td>อิ ตุ๊ด ใคร เมีย มึง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>9175</td>\n",
              "      <td>บิทแฮปปี้โรสเดย์โซฮี</td>\n",
              "      <td>0</td>\n",
              "      <td>บิท แฮปปี้ โร ส เดย์ โซ ฮี</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>6690</td>\n",
              "      <td>ปั่นปั่นปั่นกลับบ้านแฮปปี้พ่อแม่ไม่ดุไม่บ่นบ้า...</td>\n",
              "      <td>0</td>\n",
              "      <td>ปั่น ปั่น ปั่น กลับบ้าน แฮปปี้ พ่อแม่ ไม่ ดุ ไ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3766</td>\n",
              "      <td>โอ๊ยๆๆๆอิตุ๊ดเด็กกรุขำหนักมากจริงๆอิดอกจะอ้วกก...</td>\n",
              "      <td>1</td>\n",
              "      <td>โอ๊ย อิ ตุ๊ด เด็ก กรุ ขำ หนัก มาก จริง อิด อก ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>952</td>\n",
              "      <td>คนแบบนายเอกนิยายมันมีจริงนะนี่เคยเจอเป็นผชตัวเ...</td>\n",
              "      <td>1</td>\n",
              "      <td>คน แบบ นาย เอก นิยาย มัน มี จริง นะ นี่ เคย เจ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2733</td>\n",
              "      <td>ปีนี้แฮปปี้มากๆเลยนะ</td>\n",
              "      <td>0</td>\n",
              "      <td>ปี นี้ แฮปปี้ มาก เลย นะ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5e7d81e-01f0-4662-92dc-421a310339b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5e7d81e-01f0-4662-92dc-421a310339b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5e7d81e-01f0-4662-92dc-421a310339b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef3a94c3-33bb-411f-ae32-7d0feeda967f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef3a94c3-33bb-411f-ae32-7d0feeda967f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef3a94c3-33bb-411f-ae32-7d0feeda967f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20047,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2852,\n        \"min\": 0,\n        \"max\": 10013,\n        \"num_unique_values\": 10013,\n        \"samples\": [\n          3563,\n          6763,\n          6183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16749,\n        \"samples\": [\n          \"\\u0e04\\u0e38\\u0e22\\u0e01\\u0e31\\u0e1a\\u0e2d\\u0e34\\u0e15\\u0e38\\u0e4a\\u0e14\\u0e41\\u0e25\\u0e30\\u0e1e\\u0e27\\u0e01\\u0e1e\\u0e49\\u0e2d\\u0e07\\u0e17\\u0e35\\u0e48\\u0e44\\u0e1b\\u0e14\\u0e39\\u0e21\\u0e32\\u0e27\\u0e31\\u0e19\\u0e19\\u0e35\\u0e49\\u0e17\\u0e38\\u0e01\\u0e04\\u0e19\\u0e1a\\u0e2d\\u0e01\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e40\\u0e2a\\u0e35\\u0e22\\u0e07\\u0e40\\u0e14\\u0e35\\u0e22\\u0e27\\u0e01\\u0e31\\u0e19\\u0e27\\u0e48\\u0e32\\u0e41\\u0e1f\\u0e0a\\u0e1e\\u0e22\\u0e32\\u0e22\\u0e32\\u0e21\\u0e01\\u0e4a\\u0e2d\\u0e1b\\u0e04\\u0e32\\u0e41\\u0e23\\u0e4a\\u0e04\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\u0e2a\\u0e44\\u0e1b\\u0e14\\u0e35\\u0e49\\u0e41\\u0e15\\u0e48\\u0e1e\\u0e31\\u0e07\\u0e21\\u0e32\\u0e01\\u0e42\\u0e0a\\u0e04\\u0e14\\u0e35\\u0e17\\u0e35\\u0e48\\u0e2e\\u0e35\\u0e42\\u0e23\\u0e48\\u0e40\\u0e1b\\u0e49\\u0e32\\u0e15\\u0e38\\u0e07\\u0e17\\u0e38\\u0e01\\u0e04\\u0e19\\u0e40\\u0e25\\u0e22\\u0e44\\u0e21\\u0e48\\u0e27\\u0e34\\u0e08\\u0e32\\u0e23\\u0e2d\\u0e30\\u0e44\\u0e23\\u0e21\\u0e32\\u0e01\\u0e2d\\u0e34\\u0e1e\\u0e27\\u0e01\\u0e19\\u0e35\\u0e49\",\n          \"\\u0e2e\\u0e37\\u0e2d\\u0e2d\\u0e2d\\u0e2d\\u0e2d\\u0e2d\\u0e2d\\u0e34\\u0e15\\u0e38\\u0e4a\\u0e14\\u0e40\\u0e14\\u0e47\\u0e01\\u0e2d\\u0e34\\u0e15\\u0e31\\u0e27\\u0e41\\u0e2a\\u0e1a\\u0e2d\\u0e30\\u0e44\\u0e23\\u0e04\\u0e37\\u0e2d\\u0e01\\u0e32\\u0e23\\u0e1b\\u0e31\\u0e49\\u0e19\\u0e02\\u0e35\\u0e49\\u0e21\\u0e39\\u0e01\\u0e21\\u0e32\\u0e43\\u0e2b\\u0e49\\u0e14\\u0e39\\u0e15\\u0e25\\u0e01\\u0e21\\u0e32\\u0e01\\u0e21\\u0e31\\u0e49\\u0e22\",\n          \"\\u0e41\\u0e2e\\u0e1b\\u0e1b\\u0e35\\u0e49\\u0e40\\u0e1a\\u0e34\\u0e23\\u0e4c\\u0e14\\u0e40\\u0e14\\u0e22\\u0e4c\\u0e19\\u0e49\\u0e2d\\u0e07\\u0e25\\u0e34\\u0e25\\u0e25\\u0e35\\u0e48\\u0e22\\u0e49\\u0e2d\\u0e19\\u0e2b\\u0e25\\u0e31\\u0e07\\u0e21\\u0e34\\u0e27\\u0e28\\u0e38\\u0e20\\u0e28\\u0e34\\u0e29\\u0e0f\\u0e4c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16726,\n        \"samples\": [\n          \"\\u0e41\\u0e04\\u0e48 \\u0e40\\u0e1b\\u0e25\\u0e35\\u0e48\\u0e22\\u0e19 \\u0e42\\u0e23\\u0e07\\u0e41\\u0e23\\u0e21 \\u0e0a\\u0e35\\u0e27\\u0e34\\u0e15 \\u0e40\\u0e1b\\u0e25\\u0e35\\u0e48\\u0e22\\u0e19 \\u0e40\\u0e07\\u0e34\\u0e19 \\u0e44\\u0e2b\\u0e25 \\u0e2d\\u0e2d\\u0e01\\u0e08\\u0e32\\u0e01 \\u0e40\\u0e1b\\u0e4b\\u0e32 \\u0e40\\u0e2b\\u0e21\\u0e37\\u0e2d\\u0e19 \\u0e19\\u0e49\\u0e33\\u0e1b\\u0e48\\u0e32 \\u0e04\\u0e48\\u0e32 \\u0e42\\u0e23\\u0e07\\u0e41\\u0e23\\u0e21 \\u0e1a\\u0e31\\u0e15\\u0e23 \\u0e04\\u0e2d\\u0e19 \\u0e41\\u0e2e\\u0e1b\\u0e1b\\u0e35\\u0e49 \\u0e0a\\u0e35\\u0e27\\u0e34\\u0e15 \\u0e14\\u0e35 \\u0e14\\u0e35\\u0e49\",\n          \"\\u0e40\\u0e07\\u0e34\\u0e19 \\u0e40\\u0e02\\u0e49\\u0e32 \\u0e40\\u0e23\\u0e32 \\u0e0a\\u0e37\\u0e48\\u0e19\\u0e43\\u0e08 \\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21\\u0e2a\\u0e38\\u0e02 \\u0e41\\u0e2e\\u0e1b\\u0e1b\\u0e35\\u0e49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "AZwtFfPWmdw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "neg_df = pd.read_csv('neg.txt',sep='\\t',names=['text'], header=None)\n",
        "neg_df[\"label\"] = \"neg\"\n",
        "\n",
        "pos_df = pd.read_csv('pos.txt',sep='\\t',names=['text'], header=None)\n",
        "pos_df[\"label\"] = \"pos\"\n",
        "\n",
        "#neu_df = pd.read_csv('neu.txt',sep=';',names=['review'], header=None)\n",
        "#neu_df[\"sentiment\"] = \"neu\"\n",
        "df = pd.concat([neg_df, pos_df])\n"
      ],
      "metadata": {
        "id": "HAKSEXbPxASv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H_SV03bi6nf"
      },
      "outputs": [],
      "source": [
        "# Training configurations\n",
        "SEED = 1234\n",
        "TRAIN = False\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10\n",
        "\n",
        "# Architecture\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Bert model and its tokenizer\n",
        "# Text data\n",
        "from torchtext import data, datasets\n",
        "# Numerical computation\n",
        "import numpy as np\n",
        "# standard library\n",
        "import random\n",
        "import time\n",
        "# Configuration\n",
        "#from config import *\n",
        "\n",
        "# Set random seed for reproducible experiments\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Q48fq11tlcRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "\n",
        "def thai_clean_text(text):\n",
        "    st = \"\"\n",
        "\n",
        "    #สามารถเพิ่มโค้ด สำหรับคลีน ข้อความ เช่น ลบ emoji ออก เป็นต้น\n",
        "    text = deEmojify(text)\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    for w in word_tokenize(text):\n",
        "        st = st + w + \" \"\n",
        "\n",
        "    return  re.sub(' +', ' ', st)\n",
        "\n",
        "df['text'] = df.text.apply(thai_clean_text)\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "16iJg8ocB_l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "import functools\n",
        "import math\n",
        "\n",
        "from torchtext.data import Field, Dataset, Example\n",
        "import pandas as pd\n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
        "    def __init__(self, examples, fields, filter_pred=None):\n",
        "        \"\"\"\n",
        "        Create a dataset from a pandas dataframe of examples and Fields\n",
        "        Arguments:\n",
        "            examples pd.DataFrame: DataFrame of examples\n",
        "            fields {str: Field}: The Fields to use in this tuple. The\n",
        "                string is a field name, and the Field is the associated field.\n",
        "            filter_pred (callable or None): use only exanples for which\n",
        "                filter_pred(example) is true, or use all examples if None.\n",
        "                Default is None\n",
        "        \"\"\"\n",
        "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
        "        if filter_pred is not None:\n",
        "            self.examples = filter(filter_pred, self.examples)\n",
        "        self.fields = dict(fields)\n",
        "        # Unpack field tuples\n",
        "        for n, f in list(self.fields.items()):\n",
        "            if isinstance(n, tuple):\n",
        "                self.fields.update(zip(n, f))\n",
        "                del self.fields[n]\n",
        "\n",
        "class SeriesExample(Example):\n",
        "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def fromSeries(cls, data, fields):\n",
        "        return cls.fromdict(data.to_dict(), fields)\n",
        "\n",
        "    @classmethod\n",
        "    def fromdict(cls, data, fields):\n",
        "        ex = cls()\n",
        "\n",
        "        for key, field in fields.items():\n",
        "            if key not in data:\n",
        "                raise ValueError(\"Specified key {} was not found in \"\n",
        "                \"the input data\".format(key))\n",
        "            if field is not None:\n",
        "                setattr(ex, key, field.preprocess(data[key]))\n",
        "            else:\n",
        "                setattr(ex, key, data[key])\n",
        "        return ex"
      ],
      "metadata": {
        "id": "fOq5qfdeCDZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = df['text'].values\n",
        "labels = df['label'].values\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels,test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "SSTWZMesCFx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "6R85RcBmCHbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_token_id = 1  #เริ่มต้นประโยค\n",
        "pad_token_id = 0  #pad_id ตอนเทรนจะเติมเข้าไปกรณีบางประโยคสั้นกว่าประโยคอื่น\n",
        "unk_token_id=2 # กรณีไม่พบคำศัพท์จะแทนด้วย 2 นี้\n",
        "max_input_len = 512 # ความยาวสูงสุดที่โมเดลสามารภทำนายได้\n",
        "\n",
        "#create vocab_dict\n",
        "vocab = []\n",
        "for i in range( train_sentences.shape[0]):\n",
        "    ws = train_sentences[i].split(\" \")\n",
        "    for w in ws:\n",
        "        if w not in vocab:\n",
        "            vocab.append(w)\n"
      ],
      "metadata": {
        "id": "gb5N8WIsCJK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.sort()\n",
        "start_word_id = 3\n",
        "token_to_id = {val: (i+start_word_id) for i, val in enumerate(vocab)}\n",
        "\n",
        "token_to_id.update({'init_id': init_token_id, 'pad_id':pad_token_id,'unk_id':unk_token_id})"
      ],
      "metadata": {
        "id": "8Km0lgUJCLZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "vocab_json_object = json.dumps(token_to_id)\n",
        "with open(\"token2idx.json\", \"w\") as outfile:\n",
        "    outfile.write(vocab_json_object)"
      ],
      "metadata": {
        "id": "1fDX7eawCNnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjqcMTYRCPsm",
        "outputId": "53349f48-5b30-4a4c-bc84-2f2b0ba864a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available for running: \n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "import functools\n",
        "import math\n",
        "\n",
        "from torchtext.data import Field, Dataset, Example,LabelField\n",
        "import pandas as pd\n",
        "\n",
        "# Tokensize and crop sentence to 510 (for 1st and last token) instead of 512 (i.e. `max_input_len`)\n",
        "def tokenize_and_crop(sentence):\n",
        "  #print(sentence)\n",
        "  tokens = sentence.split(\" \")\n",
        "  tokens = tokens[:max_input_len - 2]\n",
        "  return tokens\n",
        "\n",
        "def convert_tokens_to_ids(tokens):\n",
        "    out_id = []\n",
        "    for w in tokens:\n",
        "        if w in token_to_id.keys():\n",
        "            out_id.append(token_to_id[w])\n",
        "        else:\n",
        "            out_id.append(unk_token_id) #unk word\n",
        "    if len(out_id)==0:\n",
        "        return [0]\n",
        "    return out_id\n",
        "\n",
        "def load_data():\n",
        "  text = Field(\n",
        "    batch_first=True,\n",
        "    use_vocab=False,\n",
        "    tokenize=tokenize_and_crop,\n",
        "    preprocessing=convert_tokens_to_ids,\n",
        "    init_token=init_token_id,\n",
        "    pad_token=pad_token_id,\n",
        "    unk_token=unk_token_id\n",
        "  )\n",
        "\n",
        "  label = LabelField(dtype=torch.long)\n",
        "\n",
        "\n",
        "  fields = { 'text' : text, 'label' : label }\n",
        "\n",
        "  train_ds = DataFrameDataset(df, fields)\n",
        "  _train_data, _valid_data = train_ds.split(random_state=random.seed(1234))\n",
        "\n",
        "  #แบ่งครึ่งๆ\n",
        "  test_data,valid_data = _valid_data.split(random_state=random.seed(1234),split_ratio=0.5)\n",
        "\n",
        "\n",
        "  print(f\"training examples count: {len(_train_data)}\")\n",
        "  print(f\"test examples count: {len(test_data)}\")\n",
        "  print(f\"validation examples count: {len(valid_data)}\")\n",
        "\n",
        "  label.build_vocab(_train_data)\n",
        "\n",
        "  lab_data = {v: k for k, v in label.vocab.stoi.items()}\n",
        "  with open('idx2lab.json', 'w') as f:\n",
        "      json.dump(lab_data, f)\n",
        "\n",
        "\n",
        "\n",
        "  train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n",
        "    (_train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True\n",
        "  )\n",
        "\n",
        "  return train_iter, valid_iter, test_iter"
      ],
      "metadata": {
        "id": "CWNx1NVECRyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment model contrain two-GRU layers for analyzing hidden representation\n",
        "# and a linear layer for classfification (the sigmoid is applied by the criterion during training).\n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentModel(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    vocab_size,\n",
        "    embedding_dim,\n",
        "    hidden_dim,\n",
        "    output_dim,\n",
        "    n_layers,\n",
        "    bidirectional,\n",
        "    dropout,\n",
        "    padding_id=0\n",
        "  ):\n",
        "\n",
        "    super(SentimentModel, self).__init__()\n",
        "\n",
        "    embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_id)\n",
        "\n",
        "    self.rnn = nn.GRU(\n",
        "      embedding_dim,\n",
        "      hidden_dim,\n",
        "      num_layers=n_layers,\n",
        "      bidirectional=bidirectional,\n",
        "      batch_first=True,\n",
        "      dropout=0 if n_layers < 2 else dropout\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "\n",
        "    embedded = self.embedding(text)\n",
        "    _, hidden = self.rnn(embedded)\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "    else:\n",
        "      hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "    output = self.out(hidden)\n",
        "    return output"
      ],
      "metadata": {
        "id": "LJ823dDjCVAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDDOWwEjCWU9",
        "outputId": "614d5aae-94cd-4b0e-ab28-9b5344a159ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples count: 8121\n",
            "test examples count: 1740\n",
            "validation examples count: 1740\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torchtext.data.iterator.BucketIterator at 0x7ec160c7c250>,\n",
              " <torchtext.data.iterator.BucketIterator at 0x7ec160c7c430>,\n",
              " <torchtext.data.iterator.BucketIterator at 0x7ec160c7c4c0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment model contrain two-GRU layers for analyzing hidden representation\n",
        "# and a linear layer for classfification (the sigmoid is applied by the criterion during training).\n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentModel(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    vocab_size,\n",
        "    embedding_dim,\n",
        "    hidden_dim,\n",
        "    output_dim,\n",
        "    n_layers,\n",
        "    bidirectional,\n",
        "    dropout,\n",
        "    padding_id=0\n",
        "  ):\n",
        "\n",
        "    super(SentimentModel, self).__init__()\n",
        "\n",
        "    embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_id)\n",
        "\n",
        "    self.rnn = nn.GRU(\n",
        "      embedding_dim,\n",
        "      hidden_dim,\n",
        "      num_layers=n_layers,\n",
        "      bidirectional=bidirectional,\n",
        "      batch_first=True,\n",
        "      dropout=0 if n_layers < 2 else dropout\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "\n",
        "    embedded = self.embedding(text)\n",
        "    _, hidden = self.rnn(embedded)\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "    else:\n",
        "      hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "    output = self.out(hidden)\n",
        "    return output"
      ],
      "metadata": {
        "id": "frNFaifXCY0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 3"
      ],
      "metadata": {
        "id": "GsvH70LnCbLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentModel(\n",
        "  vocab_size,\n",
        "  EMBEDDING_DIM,\n",
        "  HIDDEN_DIM,\n",
        "  OUTPUT_DIM,\n",
        "  N_LAYERS,\n",
        "  BIDIRECTIONAL,\n",
        "  DROPOUT\n",
        ")\n",
        "print(model)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "pytorch_total_params"
      ],
      "metadata": {
        "id": "XQR2Mqg7CdVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f382b64e-38dd-4f88-d345-3003f1073b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentModel(\n",
            "  (embedding): Embedding(14091, 128, padding_idx=0)\n",
            "  (rnn): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
            "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3580290"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# time taken for single epoch\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs\n",
        "\n",
        "# computes accuracy\n",
        "def calculate_accuracy2(y_pred,y_true):\n",
        "  y_pred = torch.round(y_pred)\n",
        "  #print(y_pred.argmax(-1))\n",
        "  correct = (y_true == y_pred.argmax(-1)).float()\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc\n",
        "\n",
        "# def binary_accuracy(preds, y):\n",
        "#   rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "#   correct = (rounded_preds == y).float()\n",
        "#   acc = correct.sum() / len(correct)\n",
        "#   return acc\n",
        "\n",
        "# training step\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "  # stats\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  # train mode\n",
        "  model.train()\n",
        "\n",
        "  for batch in tqdm(iterator):\n",
        "    # train step\n",
        "    optimizer.zero_grad()\n",
        "    #print(batch.review)\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = calculate_accuracy2(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # stats\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "# evaluates the model on given iterator (either\n",
        "# train_iter, valid_iter, or test_iter)\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  # evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "       #print(batch.text.shape)\n",
        "       predictions = model(batch.text).squeeze(1)\n",
        "       loss = criterion(predictions, batch.label)\n",
        "       acc = calculate_accuracy2(predictions, batch.label)\n",
        "       epoch_loss += loss.item()\n",
        "       epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "twUjLuYuCfYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, valid_iter, test_iter = load_data()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  # start time\n",
        "  start_time = time.time()\n",
        "  # train for an epoch\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "  # end time\n",
        "  end_time = time.time()\n",
        "  # stats\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  # save model if has validation loss\n",
        "  # better than last one\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'sentiment_model_gru.pt')\n",
        "  # stats\n",
        "  print(f'Epoch: {epoch+1:02}/{N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA_lV4jnChni",
        "outputId": "5dbfdc6a-6cee-45f8-f539-2395eeef2b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training examples count: 8121\n",
            "test examples count: 1740\n",
            "validation examples count: 1740\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [02:25<00:00,  1.14s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01/10 | Epoch Time: 2m 28s\n",
            "\tTrain Loss: 0.525 | Train Acc: 72.11%\n",
            "\t Val. Loss: 0.471 |  Val. Acc: 71.89%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [01:56<00:00,  1.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02/10 | Epoch Time: 2m 0s\n",
            "\tTrain Loss: 0.400 | Train Acc: 80.22%\n",
            "\t Val. Loss: 0.472 |  Val. Acc: 80.95%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [00:54<00:00,  2.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03/10 | Epoch Time: 0m 57s\n",
            "\tTrain Loss: 0.320 | Train Acc: 85.37%\n",
            "\t Val. Loss: 0.435 |  Val. Acc: 81.34%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [01:33<00:00,  1.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04/10 | Epoch Time: 1m 36s\n",
            "\tTrain Loss: 0.226 | Train Acc: 89.99%\n",
            "\t Val. Loss: 0.421 |  Val. Acc: 82.44%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [01:01<00:00,  2.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05/10 | Epoch Time: 1m 4s\n",
            "\tTrain Loss: 0.134 | Train Acc: 94.53%\n",
            "\t Val. Loss: 0.512 |  Val. Acc: 81.68%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [00:52<00:00,  2.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06/10 | Epoch Time: 0m 56s\n",
            "\tTrain Loss: 0.075 | Train Acc: 96.91%\n",
            "\t Val. Loss: 0.609 |  Val. Acc: 81.86%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 127/127 [01:11<00:00,  1.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07/10 | Epoch Time: 1m 15s\n",
            "\tTrain Loss: 0.046 | Train Acc: 98.30%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 81.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:51<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08/10 | Epoch Time: 0m 54s\n",
            "\tTrain Loss: 0.031 | Train Acc: 98.87%\n",
            "\t Val. Loss: 0.815 |  Val. Acc: 81.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:51<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09/10 | Epoch Time: 0m 54s\n",
            "\tTrain Loss: 0.013 | Train Acc: 99.59%\n",
            "\t Val. Loss: 0.875 |  Val. Acc: 82.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 127/127 [00:50<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/10 | Epoch Time: 0m 54s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.26%\n",
            "\t Val. Loss: 0.832 |  Val. Acc: 81.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loss, valid_acc = evaluate(model, valid_iter, criterion)"
      ],
      "metadata": {
        "id": "v50Y_cFRCr0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Model to ONNX\n"
      ],
      "metadata": {
        "id": "heOv-o03GDPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3muiPFYGECV",
        "outputId": "c486d558-5baa-47f0-cd70-11247975848b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehobzkQuGHCj",
        "outputId": "b993d89b-fd2c-4db7-d953-f67d7249521a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx as onnx\n",
        "import onnxruntime\n",
        "import torch"
      ],
      "metadata": {
        "id": "fpZmFU58GIAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_token_id = 1\n",
        "x = torch.tensor([[init_token_id, 5 , 6 , 7],[init_token_id, 4 , 6 , 7],[init_token_id, 4 , 6 , 7]]) #id ของคำ\n",
        "print(x)\n",
        "# Export the model to ONNX format\n",
        "onnx.export(model, x, \"sentiment_model.onnx\",\n",
        "            input_names=[\"input\"], #กำหนด ชื่อ input ตอน inference\n",
        "            output_names=[\"output\"], #กำหนด ชือ output\n",
        "            dynamic_axes={ \"input\": [0,1]})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gpN7htWGLbu",
        "outputId": "3588b5ba-6314-4f92-844a-c5632310ca3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 5, 6, 7],\n",
            "        [1, 4, 6, 7],\n",
            "        [1, 4, 6, 7]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2082: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input input\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with GRU can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the exported model using onnxruntime\n",
        "sess = onnxruntime.InferenceSession(\"sentiment_model.onnx\")\n",
        "\n",
        "# Perform inference using the exported model\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = sess.get_outputs()[0].name\n",
        "print(input_name,output_name)\n",
        "result = sess.run([output_name], {input_name: x.numpy()})\n",
        "print(result[0])\n",
        "lab_index = np.argmax(result[0],axis=1)\n",
        "print(result)\n",
        "print(lab_index)\n",
        "print(input_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry0z0RvLGZ-D",
        "outputId": "c3f8ef29-49b6-41a7-f830-60b53e298eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input output\n",
            "[[-1.8210903  2.562552 ]\n",
            " [-1.7566566  2.3101733]\n",
            " [-1.7566566  2.3101733]]\n",
            "[array([[-1.8210903,  2.562552 ],\n",
            "       [-1.7566566,  2.3101733],\n",
            "       [-1.7566566,  2.3101733]], dtype=float32)]\n",
            "[1 1 1]\n",
            "input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Web API"
      ],
      "metadata": {
        "id": "EUb82A3TGc1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "python -m http.server\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fb7T0EpOKjGT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2ceBesTGdfh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}